{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc4deb8",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING\n",
    "refers to transformation of cleaned raw data into features that are suitable for modeling.feature engineering can be divided  into three:\n",
    "    \n",
    "    1.FEATURE EXTRACTION\n",
    "    \n",
    "    \n",
    "    2.FEATURE TRANSFORMATION\n",
    "    \n",
    "    \n",
    "    3.FEATURE SELECTION\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15888e7",
   "metadata": {},
   "source": [
    "# steps when creating a model\n",
    "data collection--> data cleaning-->data visualization-->feature engineering--->ml model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473534b",
   "metadata": {},
   "source": [
    "# 1.FEATURE TRANSFORMATION\n",
    "This involves changing the feature from one form to another since the cmpoter only understand numeric values but for categorical values we have to transform them  to numeric e.g 0's and 1's and so as to improve the accuracy of the model.\n",
    "transformation can be done in two ways that are\n",
    "\n",
    "a) feature encoding > its where we convert the categorical variables to   numerical values\n",
    "\n",
    "b) Feature scaling >where we make the features to be in the same  scale/range,there are two ways of scaling the data which includes.\n",
    "\n",
    "   i) NORMALIZATION \n",
    "   \n",
    "   ii) STANDARDIZATION \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d37da",
   "metadata": {},
   "source": [
    "# 2.FEATURE EXTRACTION\n",
    "Feature extraction is a method for creating a new and smaller set of features that captures most of the useful information of raw data.these raw data can be where we can extract the features ca be text,images,web data etc.\n",
    "\n",
    "-we extract useful features from existing clean raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ce4fa",
   "metadata": {},
   "source": [
    "# 3. FEATURE SELECTION\n",
    "\n",
    "- it is where we select the best features which are most relevant to our machine model\n",
    "\n",
    "- Choosing a subset of the original pool of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aae06e",
   "metadata": {},
   "source": [
    "# FEATURE TRAOSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19b59e",
   "metadata": {},
   "source": [
    "# A)   ENCODING\n",
    "\n",
    "Machine learning cannot work with the categorical variables since its biased to the language that we use. we can generally divide categorical variables  into three types\n",
    "\n",
    "* binary  features > yes/no, true or false \n",
    "\n",
    "\n",
    "* ordinal features > there are specific ordered groups e.g (education level) phd can be ranked as 2, mastters can be ranked as 1, degree can be ranked as 0 , also (income level) as low income, middle income,high income\n",
    "\n",
    "\n",
    "* norminal features >there are unordered  groups  that is there are no order to be followed e.g gender, age, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378ed32",
   "metadata": {},
   "source": [
    "#  i)  Encoding  of binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91aab5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2f9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "df=pd.read_csv(\"breast-cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9b8ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3ad702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd9f0ef1",
   "metadata": {},
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d7fc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb05356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the diagnosis column where it has binary features either maligant or benign \n",
    "y=df[\"diagnosis\"].apply(lambda y_value:0 if y_value == \"B\" else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42da4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "5      1\n",
      "6      1\n",
      "7      1\n",
      "8      1\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     1\n",
      "28     1\n",
      "29     1\n",
      "30     1\n",
      "31     1\n",
      "32     1\n",
      "33     1\n",
      "34     1\n",
      "35     1\n",
      "36     1\n",
      "37     0\n",
      "38     1\n",
      "39     1\n",
      "40     1\n",
      "41     1\n",
      "42     1\n",
      "43     1\n",
      "44     1\n",
      "45     1\n",
      "46     0\n",
      "47     1\n",
      "48     0\n",
      "49     0\n",
      "50     0\n",
      "51     0\n",
      "52     0\n",
      "53     1\n",
      "54     1\n",
      "55     0\n",
      "56     1\n",
      "57     1\n",
      "58     0\n",
      "59     0\n",
      "60     0\n",
      "61     0\n",
      "62     1\n",
      "63     0\n",
      "64     1\n",
      "65     1\n",
      "66     0\n",
      "67     0\n",
      "68     0\n",
      "69     0\n",
      "70     1\n",
      "71     0\n",
      "72     1\n",
      "73     1\n",
      "74     0\n",
      "75     1\n",
      "76     0\n",
      "77     1\n",
      "78     1\n",
      "79     0\n",
      "80     0\n",
      "81     0\n",
      "82     1\n",
      "83     1\n",
      "84     0\n",
      "85     1\n",
      "86     1\n",
      "87     1\n",
      "88     0\n",
      "89     0\n",
      "90     0\n",
      "91     1\n",
      "92     0\n",
      "93     0\n",
      "94     1\n",
      "95     1\n",
      "96     0\n",
      "97     0\n",
      "98     0\n",
      "99     1\n",
      "100    1\n",
      "101    0\n",
      "102    0\n",
      "103    0\n",
      "104    0\n",
      "105    1\n",
      "106    0\n",
      "107    0\n",
      "108    1\n",
      "109    0\n",
      "110    0\n",
      "111    0\n",
      "112    0\n",
      "113    0\n",
      "114    0\n",
      "115    0\n",
      "116    0\n",
      "117    1\n",
      "118    1\n",
      "119    1\n",
      "120    0\n",
      "121    1\n",
      "122    1\n",
      "123    0\n",
      "124    0\n",
      "125    0\n",
      "126    1\n",
      "127    1\n",
      "128    0\n",
      "129    1\n",
      "130    0\n",
      "131    1\n",
      "132    1\n",
      "133    0\n",
      "134    1\n",
      "135    1\n",
      "136    0\n",
      "137    0\n",
      "138    1\n",
      "139    0\n",
      "140    0\n",
      "141    1\n",
      "142    0\n",
      "143    0\n",
      "144    0\n",
      "145    0\n",
      "146    1\n",
      "147    0\n",
      "148    0\n",
      "149    0\n",
      "150    0\n",
      "151    0\n",
      "152    0\n",
      "153    0\n",
      "154    0\n",
      "155    0\n",
      "156    1\n",
      "157    0\n",
      "158    0\n",
      "159    0\n",
      "160    0\n",
      "161    1\n",
      "162    1\n",
      "163    0\n",
      "164    1\n",
      "165    0\n",
      "166    0\n",
      "167    1\n",
      "168    1\n",
      "169    0\n",
      "170    0\n",
      "171    1\n",
      "172    1\n",
      "173    0\n",
      "174    0\n",
      "175    0\n",
      "176    0\n",
      "177    1\n",
      "178    0\n",
      "179    0\n",
      "180    1\n",
      "181    1\n",
      "182    1\n",
      "183    0\n",
      "184    1\n",
      "185    0\n",
      "186    1\n",
      "187    0\n",
      "188    0\n",
      "189    0\n",
      "190    1\n",
      "191    0\n",
      "192    0\n",
      "193    1\n",
      "194    1\n",
      "195    0\n",
      "196    1\n",
      "197    1\n",
      "198    1\n",
      "199    1\n",
      "200    0\n",
      "201    1\n",
      "202    1\n",
      "203    1\n",
      "204    0\n",
      "205    1\n",
      "206    0\n",
      "207    1\n",
      "208    0\n",
      "209    0\n",
      "210    1\n",
      "211    0\n",
      "212    1\n",
      "213    1\n",
      "214    1\n",
      "215    1\n",
      "216    0\n",
      "217    0\n",
      "218    1\n",
      "219    1\n",
      "220    0\n",
      "221    0\n",
      "222    0\n",
      "223    1\n",
      "224    0\n",
      "225    0\n",
      "226    0\n",
      "227    0\n",
      "228    0\n",
      "229    1\n",
      "230    1\n",
      "231    0\n",
      "232    0\n",
      "233    1\n",
      "234    0\n",
      "235    0\n",
      "236    1\n",
      "237    1\n",
      "238    0\n",
      "239    1\n",
      "240    0\n",
      "241    0\n",
      "242    0\n",
      "243    0\n",
      "244    1\n",
      "245    0\n",
      "246    0\n",
      "247    0\n",
      "248    0\n",
      "249    0\n",
      "250    1\n",
      "251    0\n",
      "252    1\n",
      "253    1\n",
      "254    1\n",
      "255    1\n",
      "256    1\n",
      "257    1\n",
      "258    1\n",
      "259    1\n",
      "260    1\n",
      "261    1\n",
      "262    1\n",
      "263    1\n",
      "264    1\n",
      "265    1\n",
      "266    0\n",
      "267    0\n",
      "268    0\n",
      "269    0\n",
      "270    0\n",
      "271    0\n",
      "272    1\n",
      "273    0\n",
      "274    1\n",
      "275    0\n",
      "276    0\n",
      "277    1\n",
      "278    0\n",
      "279    0\n",
      "280    1\n",
      "281    0\n",
      "282    1\n",
      "283    1\n",
      "284    0\n",
      "285    0\n",
      "286    0\n",
      "287    0\n",
      "288    0\n",
      "289    0\n",
      "290    0\n",
      "291    0\n",
      "292    0\n",
      "293    0\n",
      "294    0\n",
      "295    0\n",
      "296    0\n",
      "297    1\n",
      "298    0\n",
      "299    0\n",
      "300    1\n",
      "301    0\n",
      "302    1\n",
      "303    0\n",
      "304    0\n",
      "305    0\n",
      "306    0\n",
      "307    0\n",
      "308    0\n",
      "309    0\n",
      "310    0\n",
      "311    0\n",
      "312    0\n",
      "313    0\n",
      "314    0\n",
      "315    0\n",
      "316    0\n",
      "317    1\n",
      "318    0\n",
      "319    0\n",
      "320    0\n",
      "321    1\n",
      "322    0\n",
      "323    1\n",
      "324    0\n",
      "325    0\n",
      "326    0\n",
      "327    0\n",
      "328    1\n",
      "329    1\n",
      "330    1\n",
      "331    0\n",
      "332    0\n",
      "333    0\n",
      "334    0\n",
      "335    1\n",
      "336    0\n",
      "337    1\n",
      "338    0\n",
      "339    1\n",
      "340    0\n",
      "341    0\n",
      "342    0\n",
      "343    1\n",
      "344    0\n",
      "345    0\n",
      "346    0\n",
      "347    0\n",
      "348    0\n",
      "349    0\n",
      "350    0\n",
      "351    1\n",
      "352    1\n",
      "353    1\n",
      "354    0\n",
      "355    0\n",
      "356    0\n",
      "357    0\n",
      "358    0\n",
      "359    0\n",
      "360    0\n",
      "361    0\n",
      "362    0\n",
      "363    0\n",
      "364    0\n",
      "365    1\n",
      "366    1\n",
      "367    0\n",
      "368    1\n",
      "369    1\n",
      "370    1\n",
      "371    0\n",
      "372    1\n",
      "373    1\n",
      "374    0\n",
      "375    0\n",
      "376    0\n",
      "377    0\n",
      "378    0\n",
      "379    1\n",
      "380    0\n",
      "381    0\n",
      "382    0\n",
      "383    0\n",
      "384    0\n",
      "385    1\n",
      "386    0\n",
      "387    0\n",
      "388    0\n",
      "389    1\n",
      "390    0\n",
      "391    0\n",
      "392    1\n",
      "393    1\n",
      "394    0\n",
      "395    0\n",
      "396    0\n",
      "397    0\n",
      "398    0\n",
      "399    0\n",
      "400    1\n",
      "401    0\n",
      "402    0\n",
      "403    0\n",
      "404    0\n",
      "405    0\n",
      "406    0\n",
      "407    0\n",
      "408    1\n",
      "409    0\n",
      "410    0\n",
      "411    0\n",
      "412    0\n",
      "413    0\n",
      "414    1\n",
      "415    0\n",
      "416    0\n",
      "417    1\n",
      "418    0\n",
      "419    0\n",
      "420    0\n",
      "421    0\n",
      "422    0\n",
      "423    0\n",
      "424    0\n",
      "425    0\n",
      "426    0\n",
      "427    0\n",
      "428    0\n",
      "429    0\n",
      "430    1\n",
      "431    0\n",
      "432    1\n",
      "433    1\n",
      "434    0\n",
      "435    1\n",
      "436    0\n",
      "437    0\n",
      "438    0\n",
      "439    0\n",
      "440    0\n",
      "441    1\n",
      "442    0\n",
      "443    0\n",
      "444    1\n",
      "445    0\n",
      "446    1\n",
      "447    0\n",
      "448    0\n",
      "449    1\n",
      "450    0\n",
      "451    1\n",
      "452    0\n",
      "453    0\n",
      "454    0\n",
      "455    0\n",
      "456    0\n",
      "457    0\n",
      "458    0\n",
      "459    0\n",
      "460    1\n",
      "461    1\n",
      "462    0\n",
      "463    0\n",
      "464    0\n",
      "465    0\n",
      "466    0\n",
      "467    0\n",
      "468    1\n",
      "469    0\n",
      "470    0\n",
      "471    0\n",
      "472    0\n",
      "473    0\n",
      "474    0\n",
      "475    0\n",
      "476    0\n",
      "477    0\n",
      "478    0\n",
      "479    1\n",
      "480    0\n",
      "481    0\n",
      "482    0\n",
      "483    0\n",
      "484    0\n",
      "485    0\n",
      "486    0\n",
      "487    1\n",
      "488    0\n",
      "489    1\n",
      "490    0\n",
      "491    0\n",
      "492    1\n",
      "493    0\n",
      "494    0\n",
      "495    0\n",
      "496    0\n",
      "497    0\n",
      "498    1\n",
      "499    1\n",
      "500    0\n",
      "501    1\n",
      "502    0\n",
      "503    1\n",
      "504    0\n",
      "505    0\n",
      "506    0\n",
      "507    0\n",
      "508    0\n",
      "509    1\n",
      "510    0\n",
      "511    0\n",
      "512    1\n",
      "513    0\n",
      "514    1\n",
      "515    0\n",
      "516    1\n",
      "517    1\n",
      "518    0\n",
      "519    0\n",
      "520    0\n",
      "521    1\n",
      "522    0\n",
      "523    0\n",
      "524    0\n",
      "525    0\n",
      "526    0\n",
      "527    0\n",
      "528    0\n",
      "529    0\n",
      "530    0\n",
      "531    0\n",
      "532    0\n",
      "533    1\n",
      "534    0\n",
      "535    1\n",
      "536    1\n",
      "537    0\n",
      "538    0\n",
      "539    0\n",
      "540    0\n",
      "541    0\n",
      "542    0\n",
      "543    0\n",
      "544    0\n",
      "545    0\n",
      "546    0\n",
      "547    0\n",
      "548    0\n",
      "549    0\n",
      "550    0\n",
      "551    0\n",
      "552    0\n",
      "553    0\n",
      "554    0\n",
      "555    0\n",
      "556    0\n",
      "557    0\n",
      "558    0\n",
      "559    0\n",
      "560    0\n",
      "561    0\n",
      "562    1\n",
      "563    1\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n"
     ]
    }
   ],
   "source": [
    "print(y.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62562a7c",
   "metadata": {},
   "source": [
    "#  ii)  encoding of ordinal features\n",
    "ordinal features there are those features can be  ordered/ranked. to transform this features we use two methods that assign integer based on alphabetic ordering.\n",
    "\n",
    "* OrdinalEncorder\n",
    "\n",
    "* LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0518b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  education level\n",
       "0        bachelor\n",
       "1             phd\n",
       "2          master\n",
       "3        bachelor\n",
       "4             phd\n",
       "5          master"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "mydataframe={\"education level\":[\"bachelor\",\"phd\",\"master\",\"bachelor\",\"phd\",\"master\"]}\n",
    "x=pd.DataFrame(mydataframe)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47be273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17959d77",
   "metadata": {},
   "source": [
    "# >OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c28023b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=OrdinalEncoder()\n",
    "y.fit_transform(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1610b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['bachelor', 'master', 'phd'], dtype=object)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8b8cd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maintaining the order in terms of alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3583fb1",
   "metadata": {},
   "source": [
    "# >> LabelEncoder\n",
    "it is a technique where each label is assigned a unique integer based on alphabetical ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d5af249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7728b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit_transform(x.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c74b82",
   "metadata": {},
   "source": [
    "# comparison between labelencoder and ordinalencoder\n",
    "\n",
    "* ordinalencoder is used in encoding features(2D) while labelencoder is used in converting target variables(1D)\n",
    "\n",
    "\n",
    "* OrdinalEncoder is for 2D data shape while labelEncoder is for 1D array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5bcf9",
   "metadata": {},
   "source": [
    "# iii) Encoding of nominal features\n",
    "norminal features are those features that do not have any ordering e.g gender,city,location etc.\n",
    "\n",
    "in encoding norminal features we use technique known as one_hot_encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb91ed5",
   "metadata": {},
   "source": [
    "# One_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc1b598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data=pd.read_csv(\"IRIS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b1291b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fed23d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ae62e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ba2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68dec60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc=OneHotEncoder()\n",
    "dx=enc.fit_transform(data.species.values.reshape(-1,1)).toarray()\n",
    "dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8b24e",
   "metadata": {},
   "source": [
    "# B.feature scalling\n",
    "it is one of the important preprocessing method required for standardization/normalization of input data.\n",
    "\n",
    "why do we have to scale the data?\n",
    "\n",
    "we scale the data to ensure that our model is not biased by considering the column with higher range of values and treat that column as  important than others/give it a higher prioty.therefore scaling tries to  makes our features to be in the same range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba325ebe",
   "metadata": {},
   "source": [
    "# feature scaling techniques\n",
    "we use the following techniques when scaling the data\n",
    "\n",
    "a) standardization\n",
    "\n",
    " - scaling data to fit a standard normal distribution by making the mean to 0 and standard deviation to 1\n",
    " \n",
    "\n",
    "b) normalization\n",
    "\n",
    " - making all the features in the range of 0 to 1\n",
    " \n",
    " - it is also called min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd2794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bfebc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68313c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "731c0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "x=df.drop(\"Outcome\",axis=1)\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b87363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34f7bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8efcfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library for test train split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2267d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fd94d",
   "metadata": {},
   "source": [
    "# normalization\n",
    "we use  minmaxscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f2f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library for scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0f2f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=MinMaxScaler()\n",
    "z=scale.fit_transform(x)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cb62bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  ... 0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 ... 0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 ... 0.347 0.254 0.183]\n",
      " ...\n",
      " [0.294 0.608 0.59  ... 0.39  0.071 0.15 ]\n",
      " [0.059 0.633 0.492 ... 0.449 0.116 0.433]\n",
      " [0.059 0.467 0.574 ... 0.453 0.101 0.033]]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d0734",
   "metadata": {},
   "source": [
    "# standardization\n",
    "we use standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec43b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "055b6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=StandardScaler()\n",
    "z=scale.fit_transform(x)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84201591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15  ...  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161 ... -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 ... -1.103  0.604 -0.106]\n",
      " ...\n",
      " [ 0.343  0.003  0.15  ... -0.735 -0.685 -0.276]\n",
      " [-0.845  0.16  -0.471 ... -0.24  -0.371  1.171]\n",
      " [-0.845 -0.873  0.046 ... -0.202 -0.474 -0.871]]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83472689",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6c0f0",
   "metadata": {},
   "source": [
    "Feature engineering\n",
    "\n",
    "                    > feature transformation\n",
    "         \n",
    "                    >feature extraction\n",
    "                    \n",
    "                    >feature selection\n",
    "                    \n",
    "feature transformation\n",
    "\n",
    "                       >encoding\n",
    "                       \n",
    "                       >scaling\n",
    "                     \n",
    " Encoding\n",
    "         \n",
    "         >binary feature(yes/no)\n",
    "         \n",
    "         >ordinalfeatures(ordered)\n",
    "         \n",
    "               *ordinalencoder\n",
    "               \n",
    "               *labelencoder\n",
    "         \n",
    "         >nominal features(unordered)\n",
    "                \n",
    "                 *one_hot_encoding\n",
    "                \n",
    " scaling\n",
    "        \n",
    "         >nornalization(minmaxscaler)\n",
    "         \n",
    "         >standardization(standardscaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f240d",
   "metadata": {},
   "source": [
    "# END\n",
    "HAPPY LEARNING!\n",
    "\n",
    "HAPPY CODING!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bf5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316d89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5944b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a036b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f9698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
